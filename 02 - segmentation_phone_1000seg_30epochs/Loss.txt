Starting at epoch 0. LR=0.001

Checkpoint Path: phone20241202T0909/mask_rcnn_phone_{epoch:04d}.h5
Selecting layers to train
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
rpn_model              (Functional)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
364/364 [==============================] - ETA: 0s - batch: 181.5000 - size: 2.0000 - loss: 0.4833 - rpn_class_loss: 0.0162 - rpn_bbox_loss: 0.1514 - mrcnn_class_loss: 0.0291 - mrcnn_bbox_loss: 0.1211 - mrcnn_mask_loss: 0.1654/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
364/364 [==============================] - 1694s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.4833 - rpn_class_loss: 0.0162 - rpn_bbox_loss: 0.1514 - mrcnn_class_loss: 0.0291 - mrcnn_bbox_loss: 0.1211 - mrcnn_mask_loss: 0.1654 - val_loss: 1.1557 - val_rpn_class_loss: 0.0190 - val_rpn_bbox_loss: 0.5574 - val_mrcnn_class_loss: 0.0423 - val_mrcnn_bbox_loss: 0.1841 - val_mrcnn_mask_loss: 0.3529
Epoch 2/30
364/364 [==============================] - 1637s 4s/step - batch: 181.5000 - size: 2.0000 - loss: 0.3524 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.1605 - mrcnn_class_loss: 0.0206 - mrcnn_bbox_loss: 0.0542 - mrcnn_mask_loss: 0.1052 - val_loss: 1.2615 - val_rpn_class_loss: 0.0112 - val_rpn_bbox_loss: 0.6228 - val_mrcnn_class_loss: 0.0630 - val_mrcnn_bbox_loss: 0.2068 - val_mrcnn_mask_loss: 0.3577
Epoch 3/30
364/364 [==============================] - 1651s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.2458 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.1100 - mrcnn_class_loss: 0.0178 - mrcnn_bbox_loss: 0.0338 - mrcnn_mask_loss: 0.0750 - val_loss: 1.0333 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.5270 - val_mrcnn_class_loss: 0.0651 - val_mrcnn_bbox_loss: 0.1832 - val_mrcnn_mask_loss: 0.2419
Epoch 4/30
364/364 [==============================] - 1644s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.2037 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0912 - mrcnn_class_loss: 0.0166 - mrcnn_bbox_loss: 0.0272 - mrcnn_mask_loss: 0.0618 - val_loss: 1.0721 - val_rpn_class_loss: 0.0161 - val_rpn_bbox_loss: 0.3868 - val_mrcnn_class_loss: 0.1324 - val_mrcnn_bbox_loss: 0.2109 - val_mrcnn_mask_loss: 0.3259
Epoch 5/30
364/364 [==============================] - 1651s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1870 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.0813 - mrcnn_class_loss: 0.0179 - mrcnn_bbox_loss: 0.0284 - mrcnn_mask_loss: 0.0527 - val_loss: 1.9782 - val_rpn_class_loss: 0.0219 - val_rpn_bbox_loss: 1.2497 - val_mrcnn_class_loss: 0.0853 - val_mrcnn_bbox_loss: 0.2521 - val_mrcnn_mask_loss: 0.3691
Epoch 6/30
364/364 [==============================] - 1659s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1623 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.0741 - mrcnn_class_loss: 0.0120 - mrcnn_bbox_loss: 0.0236 - mrcnn_mask_loss: 0.0471 - val_loss: 1.4857 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 0.8134 - val_mrcnn_class_loss: 0.0739 - val_mrcnn_bbox_loss: 0.2009 - val_mrcnn_mask_loss: 0.3809
Epoch 7/30
364/364 [==============================] - 1652s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1366 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0583 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0210 - mrcnn_mask_loss: 0.0424 - val_loss: 1.4331 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.6776 - val_mrcnn_class_loss: 0.0934 - val_mrcnn_bbox_loss: 0.2192 - val_mrcnn_mask_loss: 0.4287
Epoch 8/30
364/364 [==============================] - 1649s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1225 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0499 - mrcnn_class_loss: 0.0116 - mrcnn_bbox_loss: 0.0184 - mrcnn_mask_loss: 0.0388 - val_loss: 1.3711 - val_rpn_class_loss: 0.0173 - val_rpn_bbox_loss: 0.4440 - val_mrcnn_class_loss: 0.1342 - val_mrcnn_bbox_loss: 0.2351 - val_mrcnn_mask_loss: 0.5404
Epoch 9/30
364/364 [==============================] - 1649s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1123 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0453 - mrcnn_class_loss: 0.0080 - mrcnn_bbox_loss: 0.0185 - mrcnn_mask_loss: 0.0372 - val_loss: 1.5111 - val_rpn_class_loss: 0.0189 - val_rpn_bbox_loss: 0.6366 - val_mrcnn_class_loss: 0.1045 - val_mrcnn_bbox_loss: 0.2313 - val_mrcnn_mask_loss: 0.5198
Epoch 10/30
364/364 [==============================] - 1647s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.1046 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0432 - mrcnn_class_loss: 0.0080 - mrcnn_bbox_loss: 0.0147 - mrcnn_mask_loss: 0.0359 - val_loss: 1.2558 - val_rpn_class_loss: 0.0101 - val_rpn_bbox_loss: 0.3831 - val_mrcnn_class_loss: 0.1441 - val_mrcnn_bbox_loss: 0.2124 - val_mrcnn_mask_loss: 0.5060
Epoch 11/30
364/364 [==============================] - 1649s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0919 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0348 - mrcnn_class_loss: 0.0072 - mrcnn_bbox_loss: 0.0125 - mrcnn_mask_loss: 0.0351 - val_loss: 1.9458 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 1.0521 - val_mrcnn_class_loss: 0.0869 - val_mrcnn_bbox_loss: 0.2220 - val_mrcnn_mask_loss: 0.5683
Epoch 12/30
364/364 [==============================] - 1653s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0888 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0322 - mrcnn_class_loss: 0.0069 - mrcnn_bbox_loss: 0.0126 - mrcnn_mask_loss: 0.0351 - val_loss: 1.3180 - val_rpn_class_loss: 0.0124 - val_rpn_bbox_loss: 0.4951 - val_mrcnn_class_loss: 0.1308 - val_mrcnn_bbox_loss: 0.1978 - val_mrcnn_mask_loss: 0.4818
Epoch 13/30
364/364 [==============================] - 1657s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0835 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0263 - mrcnn_class_loss: 0.0072 - mrcnn_bbox_loss: 0.0128 - mrcnn_mask_loss: 0.0351 - val_loss: 1.9226 - val_rpn_class_loss: 0.0195 - val_rpn_bbox_loss: 1.0894 - val_mrcnn_class_loss: 0.1073 - val_mrcnn_bbox_loss: 0.2255 - val_mrcnn_mask_loss: 0.4809
Epoch 14/30
364/364 [==============================] - 1655s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0768 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0253 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.0104 - mrcnn_mask_loss: 0.0329 - val_loss: 2.1710 - val_rpn_class_loss: 0.0179 - val_rpn_bbox_loss: 1.2779 - val_mrcnn_class_loss: 0.1358 - val_mrcnn_bbox_loss: 0.1934 - val_mrcnn_mask_loss: 0.5461
Epoch 15/30
364/364 [==============================] - 1662s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0690 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0186 - mrcnn_class_loss: 0.0068 - mrcnn_bbox_loss: 0.0098 - mrcnn_mask_loss: 0.0324 - val_loss: 2.0717 - val_rpn_class_loss: 0.0170 - val_rpn_bbox_loss: 1.2588 - val_mrcnn_class_loss: 0.1441 - val_mrcnn_bbox_loss: 0.1744 - val_mrcnn_mask_loss: 0.4775
Epoch 16/30
364/364 [==============================] - 1654s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0680 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0198 - mrcnn_class_loss: 0.0059 - mrcnn_bbox_loss: 0.0088 - mrcnn_mask_loss: 0.0322 - val_loss: 2.3074 - val_rpn_class_loss: 0.0201 - val_rpn_bbox_loss: 1.5130 - val_mrcnn_class_loss: 0.1234 - val_mrcnn_bbox_loss: 0.1751 - val_mrcnn_mask_loss: 0.4758
Epoch 17/30
364/364 [==============================] - 1653s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0643 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0188 - mrcnn_class_loss: 0.0050 - mrcnn_bbox_loss: 0.0082 - mrcnn_mask_loss: 0.0312 - val_loss: 2.1720 - val_rpn_class_loss: 0.0185 - val_rpn_bbox_loss: 1.4149 - val_mrcnn_class_loss: 0.1312 - val_mrcnn_bbox_loss: 0.1751 - val_mrcnn_mask_loss: 0.4322
Epoch 18/30
364/364 [==============================] - 1671s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0642 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0188 - mrcnn_class_loss: 0.0046 - mrcnn_bbox_loss: 0.0076 - mrcnn_mask_loss: 0.0322 - val_loss: 2.1910 - val_rpn_class_loss: 0.0187 - val_rpn_bbox_loss: 1.3210 - val_mrcnn_class_loss: 0.1258 - val_mrcnn_bbox_loss: 0.1843 - val_mrcnn_mask_loss: 0.5413
Epoch 19/30
364/364 [==============================] - 1667s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0570 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0147 - mrcnn_class_loss: 0.0048 - mrcnn_bbox_loss: 0.0068 - mrcnn_mask_loss: 0.0298 - val_loss: 2.8631 - val_rpn_class_loss: 0.0230 - val_rpn_bbox_loss: 2.0993 - val_mrcnn_class_loss: 0.1345 - val_mrcnn_bbox_loss: 0.1644 - val_mrcnn_mask_loss: 0.4418
Epoch 20/30
364/364 [==============================] - 1671s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0565 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0145 - mrcnn_class_loss: 0.0037 - mrcnn_bbox_loss: 0.0075 - mrcnn_mask_loss: 0.0298 - val_loss: 2.4585 - val_rpn_class_loss: 0.0205 - val_rpn_bbox_loss: 1.5866 - val_mrcnn_class_loss: 0.1709 - val_mrcnn_bbox_loss: 0.1707 - val_mrcnn_mask_loss: 0.5096
Epoch 21/30
364/364 [==============================] - 1666s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0568 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0148 - mrcnn_class_loss: 0.0037 - mrcnn_bbox_loss: 0.0071 - mrcnn_mask_loss: 0.0301 - val_loss: 4.0961 - val_rpn_class_loss: 0.0320 - val_rpn_bbox_loss: 3.3127 - val_mrcnn_class_loss: 0.0660 - val_mrcnn_bbox_loss: 0.1711 - val_mrcnn_mask_loss: 0.5143
Epoch 22/30
364/364 [==============================] - 1659s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0578 - rpn_class_loss: 9.5290e-04 - rpn_bbox_loss: 0.0162 - mrcnn_class_loss: 0.0053 - mrcnn_bbox_loss: 0.0064 - mrcnn_mask_loss: 0.0289 - val_loss: 3.2536 - val_rpn_class_loss: 0.0276 - val_rpn_bbox_loss: 2.3973 - val_mrcnn_class_loss: 0.1252 - val_mrcnn_bbox_loss: 0.1849 - val_mrcnn_mask_loss: 0.5186
Epoch 23/30
364/364 [==============================] - 1661s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0504 - rpn_class_loss: 8.3439e-04 - rpn_bbox_loss: 0.0131 - mrcnn_class_loss: 0.0031 - mrcnn_bbox_loss: 0.0051 - mrcnn_mask_loss: 0.0281 - val_loss: 3.6937 - val_rpn_class_loss: 0.0310 - val_rpn_bbox_loss: 2.8497 - val_mrcnn_class_loss: 0.1015 - val_mrcnn_bbox_loss: 0.1448 - val_mrcnn_mask_loss: 0.5668
Epoch 24/30
364/364 [==============================] - 1671s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0430 - rpn_class_loss: 7.4998e-04 - rpn_bbox_loss: 0.0085 - mrcnn_class_loss: 0.0039 - mrcnn_bbox_loss: 0.0035 - mrcnn_mask_loss: 0.0263 - val_loss: 3.5435 - val_rpn_class_loss: 0.0309 - val_rpn_bbox_loss: 2.7024 - val_mrcnn_class_loss: 0.1501 - val_mrcnn_bbox_loss: 0.1745 - val_mrcnn_mask_loss: 0.4855
Epoch 25/30
364/364 [==============================] - 1662s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0402 - rpn_class_loss: 7.6760e-04 - rpn_bbox_loss: 0.0060 - mrcnn_class_loss: 0.0039 - mrcnn_bbox_loss: 0.0036 - mrcnn_mask_loss: 0.0258 - val_loss: 3.3266 - val_rpn_class_loss: 0.0283 - val_rpn_bbox_loss: 2.4326 - val_mrcnn_class_loss: 0.1520 - val_mrcnn_bbox_loss: 0.1879 - val_mrcnn_mask_loss: 0.5258
Epoch 26/30
364/364 [==============================] - 1658s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0421 - rpn_class_loss: 6.5440e-04 - rpn_bbox_loss: 0.0071 - mrcnn_class_loss: 0.0043 - mrcnn_bbox_loss: 0.0037 - mrcnn_mask_loss: 0.0264 - val_loss: 3.0711 - val_rpn_class_loss: 0.0260 - val_rpn_bbox_loss: 2.2435 - val_mrcnn_class_loss: 0.0940 - val_mrcnn_bbox_loss: 0.1748 - val_mrcnn_mask_loss: 0.5326
Epoch 27/30
364/364 [==============================] - 1662s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0412 - rpn_class_loss: 6.3547e-04 - rpn_bbox_loss: 0.0069 - mrcnn_class_loss: 0.0038 - mrcnn_bbox_loss: 0.0039 - mrcnn_mask_loss: 0.0259 - val_loss: 4.0083 - val_rpn_class_loss: 0.0361 - val_rpn_bbox_loss: 3.1694 - val_mrcnn_class_loss: 0.1441 - val_mrcnn_bbox_loss: 0.1557 - val_mrcnn_mask_loss: 0.5030
Epoch 28/30
364/364 [==============================] - 1669s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0394 - rpn_class_loss: 6.5830e-04 - rpn_bbox_loss: 0.0053 - mrcnn_class_loss: 0.0034 - mrcnn_bbox_loss: 0.0038 - mrcnn_mask_loss: 0.0262 - val_loss: 3.0062 - val_rpn_class_loss: 0.0280 - val_rpn_bbox_loss: 2.2103 - val_mrcnn_class_loss: 0.0965 - val_mrcnn_bbox_loss: 0.1801 - val_mrcnn_mask_loss: 0.4913
Epoch 29/30
364/364 [==============================] - 1660s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0428 - rpn_class_loss: 5.5244e-04 - rpn_bbox_loss: 0.0074 - mrcnn_class_loss: 0.0030 - mrcnn_bbox_loss: 0.0043 - mrcnn_mask_loss: 0.0275 - val_loss: 4.1804 - val_rpn_class_loss: 0.0353 - val_rpn_bbox_loss: 3.3282 - val_mrcnn_class_loss: 0.1026 - val_mrcnn_bbox_loss: 0.1917 - val_mrcnn_mask_loss: 0.5226
Epoch 30/30
364/364 [==============================] - 1664s 5s/step - batch: 181.5000 - size: 2.0000 - loss: 0.0395 - rpn_class_loss: 5.2046e-04 - rpn_bbox_loss: 0.0064 - mrcnn_class_loss: 0.0030 - mrcnn_bbox_loss: 0.0038 - mrcnn_mask_loss: 0.0258 - val_loss: 3.6965 - val_rpn_class_loss: 0.0293 - val_rpn_bbox_loss: 2.9274 - val_mrcnn_class_loss: 0.1106 - val_mrcnn_bbox_loss: 0.1671 - val_mrcnn_mask_loss: 0.4621
829.5 minutos