Starting at epoch 0. LR=0.001

Checkpoint Path: phone20241204T0309/mask_rcnn_phone_{epoch:04d}.h5
Selecting layers to train
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
rpn_model              (Functional)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
Epoch 1/20
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
249/249 [==============================] - ETA: 0s - batch: 124.0000 - size: 2.0000 - loss: 0.5790 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.1670 - mrcnn_class_loss: 0.0386 - mrcnn_bbox_loss: 0.1782 - mrcnn_mask_loss: 0.1878/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
249/249 [==============================] - 1177s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.5790 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.1670 - mrcnn_class_loss: 0.0386 - mrcnn_bbox_loss: 0.1782 - mrcnn_mask_loss: 0.1878 - val_loss: 0.9112 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.4907 - val_mrcnn_class_loss: 0.0487 - val_mrcnn_bbox_loss: 0.1544 - val_mrcnn_mask_loss: 0.2060
Epoch 2/20
249/249 [==============================] - 1121s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.2378 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0729 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.0487 - mrcnn_mask_loss: 0.0869 - val_loss: 1.0691 - val_rpn_class_loss: 0.0141 - val_rpn_bbox_loss: 0.6523 - val_mrcnn_class_loss: 0.0334 - val_mrcnn_bbox_loss: 0.1360 - val_mrcnn_mask_loss: 0.2333
Epoch 3/20
249/249 [==============================] - 1120s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.1646 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0512 - mrcnn_class_loss: 0.0151 - mrcnn_bbox_loss: 0.0327 - mrcnn_mask_loss: 0.0637 - val_loss: 0.8314 - val_rpn_class_loss: 0.0119 - val_rpn_bbox_loss: 0.3889 - val_mrcnn_class_loss: 0.0371 - val_mrcnn_bbox_loss: 0.1137 - val_mrcnn_mask_loss: 0.2799
Epoch 4/20
249/249 [==============================] - 1126s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.1335 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0504 - mrcnn_class_loss: 0.0104 - mrcnn_bbox_loss: 0.0220 - mrcnn_mask_loss: 0.0486 - val_loss: 0.8995 - val_rpn_class_loss: 0.0117 - val_rpn_bbox_loss: 0.3198 - val_mrcnn_class_loss: 0.0631 - val_mrcnn_bbox_loss: 0.1179 - val_mrcnn_mask_loss: 0.3870
Epoch 5/20
249/249 [==============================] - 1126s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.1191 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0505 - mrcnn_class_loss: 0.0095 - mrcnn_bbox_loss: 0.0140 - mrcnn_mask_loss: 0.0429 - val_loss: 0.8827 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.3056 - val_mrcnn_class_loss: 0.0743 - val_mrcnn_bbox_loss: 0.1287 - val_mrcnn_mask_loss: 0.3633
Epoch 6/20
249/249 [==============================] - 1130s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0834 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0230 - mrcnn_class_loss: 0.0072 - mrcnn_bbox_loss: 0.0113 - mrcnn_mask_loss: 0.0409 - val_loss: 1.0328 - val_rpn_class_loss: 0.0114 - val_rpn_bbox_loss: 0.3490 - val_mrcnn_class_loss: 0.0824 - val_mrcnn_bbox_loss: 0.1208 - val_mrcnn_mask_loss: 0.4691
Epoch 7/20
249/249 [==============================] - 1133s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0810 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0282 - mrcnn_class_loss: 0.0055 - mrcnn_bbox_loss: 0.0096 - mrcnn_mask_loss: 0.0367 - val_loss: 1.2417 - val_rpn_class_loss: 0.0129 - val_rpn_bbox_loss: 0.3839 - val_mrcnn_class_loss: 0.1168 - val_mrcnn_bbox_loss: 0.1640 - val_mrcnn_mask_loss: 0.5640
Epoch 8/20
249/249 [==============================] - 1129s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0632 - rpn_class_loss: 8.5245e-04 - rpn_bbox_loss: 0.0127 - mrcnn_class_loss: 0.0060 - mrcnn_bbox_loss: 0.0091 - mrcnn_mask_loss: 0.0346 - val_loss: 1.1735 - val_rpn_class_loss: 0.0159 - val_rpn_bbox_loss: 0.6816 - val_mrcnn_class_loss: 0.0661 - val_mrcnn_bbox_loss: 0.1117 - val_mrcnn_mask_loss: 0.2982
Epoch 9/20
249/249 [==============================] - 1128s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0590 - rpn_class_loss: 7.1384e-04 - rpn_bbox_loss: 0.0098 - mrcnn_class_loss: 0.0064 - mrcnn_bbox_loss: 0.0076 - mrcnn_mask_loss: 0.0344 - val_loss: 1.0754 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.5616 - val_mrcnn_class_loss: 0.0639 - val_mrcnn_bbox_loss: 0.0976 - val_mrcnn_mask_loss: 0.3362
Epoch 10/20
249/249 [==============================] - 1129s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0535 - rpn_class_loss: 6.3488e-04 - rpn_bbox_loss: 0.0084 - mrcnn_class_loss: 0.0046 - mrcnn_bbox_loss: 0.0073 - mrcnn_mask_loss: 0.0326 - val_loss: 1.2612 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.5487 - val_mrcnn_class_loss: 0.1156 - val_mrcnn_bbox_loss: 0.1353 - val_mrcnn_mask_loss: 0.4459
Epoch 11/20
249/249 [==============================] - 1133s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0508 - rpn_class_loss: 5.3677e-04 - rpn_bbox_loss: 0.0097 - mrcnn_class_loss: 0.0034 - mrcnn_bbox_loss: 0.0059 - mrcnn_mask_loss: 0.0313 - val_loss: 1.1997 - val_rpn_class_loss: 0.0145 - val_rpn_bbox_loss: 0.4377 - val_mrcnn_class_loss: 0.1375 - val_mrcnn_bbox_loss: 0.1290 - val_mrcnn_mask_loss: 0.4809
Epoch 12/20
249/249 [==============================] - 1127s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0490 - rpn_class_loss: 4.8166e-04 - rpn_bbox_loss: 0.0106 - mrcnn_class_loss: 0.0038 - mrcnn_bbox_loss: 0.0050 - mrcnn_mask_loss: 0.0291 - val_loss: 1.1783 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.5498 - val_mrcnn_class_loss: 0.0909 - val_mrcnn_bbox_loss: 0.1127 - val_mrcnn_mask_loss: 0.4093
Epoch 13/20
249/249 [==============================] - 1131s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0476 - rpn_class_loss: 4.2107e-04 - rpn_bbox_loss: 0.0089 - mrcnn_class_loss: 0.0035 - mrcnn_bbox_loss: 0.0052 - mrcnn_mask_loss: 0.0296 - val_loss: 0.9672 - val_rpn_class_loss: 0.0131 - val_rpn_bbox_loss: 0.4301 - val_mrcnn_class_loss: 0.0686 - val_mrcnn_bbox_loss: 0.1018 - val_mrcnn_mask_loss: 0.3537
Epoch 14/20
249/249 [==============================] - 1128s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0420 - rpn_class_loss: 3.6202e-04 - rpn_bbox_loss: 0.0065 - mrcnn_class_loss: 0.0033 - mrcnn_bbox_loss: 0.0045 - mrcnn_mask_loss: 0.0273 - val_loss: 1.0500 - val_rpn_class_loss: 0.0139 - val_rpn_bbox_loss: 0.4420 - val_mrcnn_class_loss: 0.0963 - val_mrcnn_bbox_loss: 0.1137 - val_mrcnn_mask_loss: 0.3840
Epoch 15/20
249/249 [==============================] - 1129s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0477 - rpn_class_loss: 4.4464e-04 - rpn_bbox_loss: 0.0096 - mrcnn_class_loss: 0.0035 - mrcnn_bbox_loss: 0.0057 - mrcnn_mask_loss: 0.0284 - val_loss: 1.0797 - val_rpn_class_loss: 0.0137 - val_rpn_bbox_loss: 0.4247 - val_mrcnn_class_loss: 0.0785 - val_mrcnn_bbox_loss: 0.1087 - val_mrcnn_mask_loss: 0.4541
Epoch 16/20
249/249 [==============================] - 1136s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0399 - rpn_class_loss: 3.6294e-04 - rpn_bbox_loss: 0.0059 - mrcnn_class_loss: 0.0027 - mrcnn_bbox_loss: 0.0046 - mrcnn_mask_loss: 0.0263 - val_loss: 1.1895 - val_rpn_class_loss: 0.0121 - val_rpn_bbox_loss: 0.3406 - val_mrcnn_class_loss: 0.1569 - val_mrcnn_bbox_loss: 0.1260 - val_mrcnn_mask_loss: 0.5540
Epoch 17/20
249/249 [==============================] - 1132s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0389 - rpn_class_loss: 3.4189e-04 - rpn_bbox_loss: 0.0063 - mrcnn_class_loss: 0.0025 - mrcnn_bbox_loss: 0.0042 - mrcnn_mask_loss: 0.0256 - val_loss: 1.0772 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 0.3738 - val_mrcnn_class_loss: 0.1168 - val_mrcnn_bbox_loss: 0.1137 - val_mrcnn_mask_loss: 0.4596
Epoch 18/20
249/249 [==============================] - 1135s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0396 - rpn_class_loss: 3.7128e-04 - rpn_bbox_loss: 0.0055 - mrcnn_class_loss: 0.0028 - mrcnn_bbox_loss: 0.0038 - mrcnn_mask_loss: 0.0271 - val_loss: 1.1521 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.3327 - val_mrcnn_class_loss: 0.1273 - val_mrcnn_bbox_loss: 0.1157 - val_mrcnn_mask_loss: 0.5644
Epoch 19/20
249/249 [==============================] - 1134s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0381 - rpn_class_loss: 3.6066e-04 - rpn_bbox_loss: 0.0055 - mrcnn_class_loss: 0.0019 - mrcnn_bbox_loss: 0.0039 - mrcnn_mask_loss: 0.0264 - val_loss: 1.2130 - val_rpn_class_loss: 0.0137 - val_rpn_bbox_loss: 0.3867 - val_mrcnn_class_loss: 0.1231 - val_mrcnn_bbox_loss: 0.1218 - val_mrcnn_mask_loss: 0.5677
Epoch 20/20
249/249 [==============================] - 1134s 5s/step - batch: 124.0000 - size: 2.0000 - loss: 0.0388 - rpn_class_loss: 2.8906e-04 - rpn_bbox_loss: 0.0063 - mrcnn_class_loss: 0.0024 - mrcnn_bbox_loss: 0.0041 - mrcnn_mask_loss: 0.0256 - val_loss: 1.2209 - val_rpn_class_loss: 0.0124 - val_rpn_bbox_loss: 0.3069 - val_mrcnn_class_loss: 0.1677 - val_mrcnn_bbox_loss: 0.1495 - val_mrcnn_mask_loss: 0.5844
377.54 minutos