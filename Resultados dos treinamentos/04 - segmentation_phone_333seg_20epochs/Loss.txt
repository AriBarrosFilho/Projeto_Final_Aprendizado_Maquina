Starting at epoch 0. LR=0.001

Checkpoint Path: phone20241204T0956/mask_rcnn_phone_{epoch:04d}.h5
Selecting layers to train
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
rpn_model              (Functional)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
Epoch 1/20
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
129/129 [==============================] - ETA: 0s - batch: 64.0000 - size: 2.0000 - loss: 0.4944 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.1537 - mrcnn_class_loss: 0.0234 - mrcnn_bbox_loss: 0.1949 - mrcnn_mask_loss: 0.1170/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
129/129 [==============================] - 626s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.4944 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.1537 - mrcnn_class_loss: 0.0234 - mrcnn_bbox_loss: 0.1949 - mrcnn_mask_loss: 0.1170 - val_loss: 0.4059 - val_rpn_class_loss: 0.0090 - val_rpn_bbox_loss: 0.1608 - val_mrcnn_class_loss: 0.0188 - val_mrcnn_bbox_loss: 0.1155 - val_mrcnn_mask_loss: 0.1018
Epoch 2/20
129/129 [==============================] - 594s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.3055 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.1821 - mrcnn_class_loss: 0.0095 - mrcnn_bbox_loss: 0.0507 - mrcnn_mask_loss: 0.0587 - val_loss: 0.3437 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.1780 - val_mrcnn_class_loss: 0.0094 - val_mrcnn_bbox_loss: 0.0625 - val_mrcnn_mask_loss: 0.0884
Epoch 3/20
129/129 [==============================] - 599s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.1658 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0722 - mrcnn_class_loss: 0.0071 - mrcnn_bbox_loss: 0.0370 - mrcnn_mask_loss: 0.0471 - val_loss: 0.2970 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.1234 - val_mrcnn_class_loss: 0.0107 - val_mrcnn_bbox_loss: 0.0489 - val_mrcnn_mask_loss: 0.1073
Epoch 4/20
129/129 [==============================] - 601s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0962 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0279 - mrcnn_class_loss: 0.0061 - mrcnn_bbox_loss: 0.0208 - mrcnn_mask_loss: 0.0395 - val_loss: 0.2950 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.1099 - val_mrcnn_class_loss: 0.0157 - val_mrcnn_bbox_loss: 0.0466 - val_mrcnn_mask_loss: 0.1184
Epoch 5/20
129/129 [==============================] - 602s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0707 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0198 - mrcnn_class_loss: 0.0053 - mrcnn_bbox_loss: 0.0081 - mrcnn_mask_loss: 0.0360 - val_loss: 0.2828 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.1017 - val_mrcnn_class_loss: 0.0121 - val_mrcnn_bbox_loss: 0.0479 - val_mrcnn_mask_loss: 0.1171
Epoch 6/20
129/129 [==============================] - 599s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0724 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0214 - mrcnn_class_loss: 0.0052 - mrcnn_bbox_loss: 0.0071 - mrcnn_mask_loss: 0.0374 - val_loss: 0.2607 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.1018 - val_mrcnn_class_loss: 0.0143 - val_mrcnn_bbox_loss: 0.0416 - val_mrcnn_mask_loss: 0.0997
Epoch 7/20
129/129 [==============================] - 599s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0637 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0207 - mrcnn_class_loss: 0.0036 - mrcnn_bbox_loss: 0.0056 - mrcnn_mask_loss: 0.0326 - val_loss: 0.2595 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.1020 - val_mrcnn_class_loss: 0.0066 - val_mrcnn_bbox_loss: 0.0345 - val_mrcnn_mask_loss: 0.1140
Epoch 8/20
129/129 [==============================] - 601s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0597 - rpn_class_loss: 8.1517e-04 - rpn_bbox_loss: 0.0195 - mrcnn_class_loss: 0.0031 - mrcnn_bbox_loss: 0.0056 - mrcnn_mask_loss: 0.0307 - val_loss: 0.3073 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.1108 - val_mrcnn_class_loss: 0.0167 - val_mrcnn_bbox_loss: 0.0416 - val_mrcnn_mask_loss: 0.1361
Epoch 9/20
129/129 [==============================] - 600s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0508 - rpn_class_loss: 7.7614e-04 - rpn_bbox_loss: 0.0119 - mrcnn_class_loss: 0.0035 - mrcnn_bbox_loss: 0.0048 - mrcnn_mask_loss: 0.0298 - val_loss: 0.2928 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.1115 - val_mrcnn_class_loss: 0.0114 - val_mrcnn_bbox_loss: 0.0366 - val_mrcnn_mask_loss: 0.1311
Epoch 10/20
129/129 [==============================] - 601s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0613 - rpn_class_loss: 7.0832e-04 - rpn_bbox_loss: 0.0208 - mrcnn_class_loss: 0.0039 - mrcnn_bbox_loss: 0.0059 - mrcnn_mask_loss: 0.0300 - val_loss: 0.2620 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.0887 - val_mrcnn_class_loss: 0.0105 - val_mrcnn_bbox_loss: 0.0402 - val_mrcnn_mask_loss: 0.1199
Epoch 11/20
129/129 [==============================] - 600s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0784 - rpn_class_loss: 7.5476e-04 - rpn_bbox_loss: 0.0380 - mrcnn_class_loss: 0.0031 - mrcnn_bbox_loss: 0.0066 - mrcnn_mask_loss: 0.0300 - val_loss: 0.3517 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1542 - val_mrcnn_class_loss: 0.0213 - val_mrcnn_bbox_loss: 0.0507 - val_mrcnn_mask_loss: 0.1228
Epoch 12/20
129/129 [==============================] - 599s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0648 - rpn_class_loss: 7.5603e-04 - rpn_bbox_loss: 0.0256 - mrcnn_class_loss: 0.0023 - mrcnn_bbox_loss: 0.0066 - mrcnn_mask_loss: 0.0295 - val_loss: 0.2769 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.0937 - val_mrcnn_class_loss: 0.0178 - val_mrcnn_bbox_loss: 0.0371 - val_mrcnn_mask_loss: 0.1252
Epoch 13/20
129/129 [==============================] - 597s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0497 - rpn_class_loss: 7.3306e-04 - rpn_bbox_loss: 0.0133 - mrcnn_class_loss: 0.0023 - mrcnn_bbox_loss: 0.0038 - mrcnn_mask_loss: 0.0295 - val_loss: 0.2901 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.0988 - val_mrcnn_class_loss: 0.0114 - val_mrcnn_bbox_loss: 0.0428 - val_mrcnn_mask_loss: 0.1340
Epoch 14/20
129/129 [==============================] - 602s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0519 - rpn_class_loss: 5.9787e-04 - rpn_bbox_loss: 0.0124 - mrcnn_class_loss: 0.0020 - mrcnn_bbox_loss: 0.0054 - mrcnn_mask_loss: 0.0314 - val_loss: 0.3286 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.1142 - val_mrcnn_class_loss: 0.0187 - val_mrcnn_bbox_loss: 0.0458 - val_mrcnn_mask_loss: 0.1470
Epoch 15/20
129/129 [==============================] - 601s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0638 - rpn_class_loss: 6.6761e-04 - rpn_bbox_loss: 0.0240 - mrcnn_class_loss: 0.0035 - mrcnn_bbox_loss: 0.0060 - mrcnn_mask_loss: 0.0296 - val_loss: 0.2855 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.0962 - val_mrcnn_class_loss: 0.0174 - val_mrcnn_bbox_loss: 0.0383 - val_mrcnn_mask_loss: 0.1304
Epoch 16/20
129/129 [==============================] - 602s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0504 - rpn_class_loss: 5.8090e-04 - rpn_bbox_loss: 0.0161 - mrcnn_class_loss: 0.0026 - mrcnn_bbox_loss: 0.0030 - mrcnn_mask_loss: 0.0281 - val_loss: 0.2924 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.0960 - val_mrcnn_class_loss: 0.0129 - val_mrcnn_bbox_loss: 0.0421 - val_mrcnn_mask_loss: 0.1387
Epoch 17/20
129/129 [==============================] - 602s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0530 - rpn_class_loss: 5.4054e-04 - rpn_bbox_loss: 0.0192 - mrcnn_class_loss: 0.0026 - mrcnn_bbox_loss: 0.0033 - mrcnn_mask_loss: 0.0274 - val_loss: 0.2921 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.0944 - val_mrcnn_class_loss: 0.0248 - val_mrcnn_bbox_loss: 0.0425 - val_mrcnn_mask_loss: 0.1275
Epoch 18/20
129/129 [==============================] - 602s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0517 - rpn_class_loss: 6.1655e-04 - rpn_bbox_loss: 0.0190 - mrcnn_class_loss: 0.0028 - mrcnn_bbox_loss: 0.0030 - mrcnn_mask_loss: 0.0263 - val_loss: 0.3037 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.0976 - val_mrcnn_class_loss: 0.0222 - val_mrcnn_bbox_loss: 0.0393 - val_mrcnn_mask_loss: 0.1421
Epoch 19/20
129/129 [==============================] - 603s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0433 - rpn_class_loss: 5.8946e-04 - rpn_bbox_loss: 0.0119 - mrcnn_class_loss: 0.0028 - mrcnn_bbox_loss: 0.0025 - mrcnn_mask_loss: 0.0256 - val_loss: 0.3103 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.0911 - val_mrcnn_class_loss: 0.0255 - val_mrcnn_bbox_loss: 0.0410 - val_mrcnn_mask_loss: 0.1505
Epoch 20/20
129/129 [==============================] - 603s 5s/step - batch: 64.0000 - size: 2.0000 - loss: 0.0369 - rpn_class_loss: 4.9939e-04 - rpn_bbox_loss: 0.0068 - mrcnn_class_loss: 0.0023 - mrcnn_bbox_loss: 0.0024 - mrcnn_mask_loss: 0.0250 - val_loss: 0.3033 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.0857 - val_mrcnn_class_loss: 0.0235 - val_mrcnn_bbox_loss: 0.0396 - val_mrcnn_mask_loss: 0.1519
200.82 minutos