Starting at epoch 0. LR=0.001

Checkpoint Path: balloon20241204T2214/mask_rcnn_balloon_{epoch:04d}.h5
Selecting layers to train
fpn_c5p5               (Conv2D)
fpn_c4p4               (Conv2D)
fpn_c3p3               (Conv2D)
fpn_c2p2               (Conv2D)
fpn_p5                 (Conv2D)
fpn_p2                 (Conv2D)
fpn_p3                 (Conv2D)
fpn_p4                 (Conv2D)
rpn_model              (Functional)
mrcnn_mask_conv1       (TimeDistributed)
mrcnn_mask_bn1         (TimeDistributed)
mrcnn_mask_conv2       (TimeDistributed)
mrcnn_mask_bn2         (TimeDistributed)
mrcnn_class_conv1      (TimeDistributed)
mrcnn_class_bn1        (TimeDistributed)
mrcnn_mask_conv3       (TimeDistributed)
mrcnn_mask_bn3         (TimeDistributed)
mrcnn_class_conv2      (TimeDistributed)
mrcnn_class_bn2        (TimeDistributed)
mrcnn_mask_conv4       (TimeDistributed)
mrcnn_mask_bn4         (TimeDistributed)
mrcnn_bbox_fc          (TimeDistributed)
mrcnn_mask_deconv      (TimeDistributed)
mrcnn_class_logits     (TimeDistributed)
mrcnn_mask             (TimeDistributed)
/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
Epoch 1/20
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0", shape=(None,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0", shape=(6000,), dtype=int32), values=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0", shape=(6000, 4), dtype=float32), dense_shape=Tensor("training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
115/115 [==============================] - ETA: 0s - batch: 57.0000 - size: 2.0000 - loss: 1.0864 - rpn_class_loss: 0.0347 - rpn_bbox_loss: 0.2368 - mrcnn_class_loss: 0.1021 - mrcnn_bbox_loss: 0.2722 - mrcnn_mask_loss: 0.4407/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
115/115 [==============================] - 565s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 1.0864 - rpn_class_loss: 0.0347 - rpn_bbox_loss: 0.2368 - mrcnn_class_loss: 0.1021 - mrcnn_bbox_loss: 0.2722 - mrcnn_mask_loss: 0.4407 - val_loss: 1.0877 - val_rpn_class_loss: 0.0126 - val_rpn_bbox_loss: 0.2931 - val_mrcnn_class_loss: 0.0350 - val_mrcnn_bbox_loss: 0.4622 - val_mrcnn_mask_loss: 0.2848
Epoch 2/20
115/115 [==============================] - 532s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.4208 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.1009 - mrcnn_class_loss: 0.0286 - mrcnn_bbox_loss: 0.1251 - mrcnn_mask_loss: 0.1495 - val_loss: 0.8125 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.3534 - val_mrcnn_class_loss: 0.0243 - val_mrcnn_bbox_loss: 0.2488 - val_mrcnn_mask_loss: 0.1785
Epoch 3/20
115/115 [==============================] - 536s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.3374 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.0923 - mrcnn_class_loss: 0.0219 - mrcnn_bbox_loss: 0.1033 - mrcnn_mask_loss: 0.1124 - val_loss: 0.7690 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.2438 - val_mrcnn_class_loss: 0.0346 - val_mrcnn_bbox_loss: 0.2011 - val_mrcnn_mask_loss: 0.2821
Epoch 4/20
115/115 [==============================] - 536s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.2303 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.0836 - mrcnn_class_loss: 0.0148 - mrcnn_bbox_loss: 0.0506 - mrcnn_mask_loss: 0.0760 - val_loss: 0.9341 - val_rpn_class_loss: 0.0131 - val_rpn_bbox_loss: 0.2784 - val_mrcnn_class_loss: 0.0527 - val_mrcnn_bbox_loss: 0.2009 - val_mrcnn_mask_loss: 0.3890
Epoch 5/20
115/115 [==============================] - 539s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1723 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0491 - mrcnn_class_loss: 0.0108 - mrcnn_bbox_loss: 0.0395 - mrcnn_mask_loss: 0.0693 - val_loss: 0.9367 - val_rpn_class_loss: 0.0093 - val_rpn_bbox_loss: 0.2649 - val_mrcnn_class_loss: 0.0956 - val_mrcnn_bbox_loss: 0.1938 - val_mrcnn_mask_loss: 0.3731
Epoch 6/20
115/115 [==============================] - 536s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1548 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0578 - mrcnn_class_loss: 0.0088 - mrcnn_bbox_loss: 0.0290 - mrcnn_mask_loss: 0.0565 - val_loss: 0.8008 - val_rpn_class_loss: 0.0104 - val_rpn_bbox_loss: 0.2779 - val_mrcnn_class_loss: 0.0911 - val_mrcnn_bbox_loss: 0.1235 - val_mrcnn_mask_loss: 0.2979
Epoch 7/20
115/115 [==============================] - 537s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1316 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0389 - mrcnn_class_loss: 0.0069 - mrcnn_bbox_loss: 0.0279 - mrcnn_mask_loss: 0.0558 - val_loss: 0.9606 - val_rpn_class_loss: 0.0082 - val_rpn_bbox_loss: 0.2503 - val_mrcnn_class_loss: 0.1306 - val_mrcnn_bbox_loss: 0.2177 - val_mrcnn_mask_loss: 0.3537
Epoch 8/20
115/115 [==============================] - 543s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1331 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0463 - mrcnn_class_loss: 0.0059 - mrcnn_bbox_loss: 0.0293 - mrcnn_mask_loss: 0.0500 - val_loss: 0.8671 - val_rpn_class_loss: 0.0099 - val_rpn_bbox_loss: 0.2481 - val_mrcnn_class_loss: 0.0948 - val_mrcnn_bbox_loss: 0.1569 - val_mrcnn_mask_loss: 0.3574
Epoch 9/20
115/115 [==============================] - 539s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1248 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0429 - mrcnn_class_loss: 0.0048 - mrcnn_bbox_loss: 0.0254 - mrcnn_mask_loss: 0.0501 - val_loss: 0.9088 - val_rpn_class_loss: 0.0122 - val_rpn_bbox_loss: 0.2623 - val_mrcnn_class_loss: 0.0926 - val_mrcnn_bbox_loss: 0.2445 - val_mrcnn_mask_loss: 0.2972
Epoch 10/20
115/115 [==============================] - 543s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1379 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0525 - mrcnn_class_loss: 0.0047 - mrcnn_bbox_loss: 0.0251 - mrcnn_mask_loss: 0.0541 - val_loss: 0.9519 - val_rpn_class_loss: 0.0085 - val_rpn_bbox_loss: 0.2377 - val_mrcnn_class_loss: 0.1087 - val_mrcnn_bbox_loss: 0.2110 - val_mrcnn_mask_loss: 0.3860
Epoch 11/20
115/115 [==============================] - 543s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1185 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0378 - mrcnn_class_loss: 0.0064 - mrcnn_bbox_loss: 0.0239 - mrcnn_mask_loss: 0.0486 - val_loss: 0.9685 - val_rpn_class_loss: 0.0099 - val_rpn_bbox_loss: 0.2804 - val_mrcnn_class_loss: 0.1085 - val_mrcnn_bbox_loss: 0.2190 - val_mrcnn_mask_loss: 0.3507
Epoch 12/20
115/115 [==============================] - 542s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1178 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0424 - mrcnn_class_loss: 0.0056 - mrcnn_bbox_loss: 0.0244 - mrcnn_mask_loss: 0.0439 - val_loss: 0.9317 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.2540 - val_mrcnn_class_loss: 0.0877 - val_mrcnn_bbox_loss: 0.2215 - val_mrcnn_mask_loss: 0.3583
Epoch 13/20
115/115 [==============================] - 541s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1148 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0433 - mrcnn_class_loss: 0.0039 - mrcnn_bbox_loss: 0.0207 - mrcnn_mask_loss: 0.0458 - val_loss: 0.9218 - val_rpn_class_loss: 0.0127 - val_rpn_bbox_loss: 0.2586 - val_mrcnn_class_loss: 0.0959 - val_mrcnn_bbox_loss: 0.1592 - val_mrcnn_mask_loss: 0.3953
Epoch 14/20
115/115 [==============================] - 541s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1153 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0441 - mrcnn_class_loss: 0.0041 - mrcnn_bbox_loss: 0.0163 - mrcnn_mask_loss: 0.0495 - val_loss: 1.0509 - val_rpn_class_loss: 0.0139 - val_rpn_bbox_loss: 0.3386 - val_mrcnn_class_loss: 0.1160 - val_mrcnn_bbox_loss: 0.1881 - val_mrcnn_mask_loss: 0.3944
Epoch 15/20
115/115 [==============================] - 544s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.0990 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0305 - mrcnn_class_loss: 0.0038 - mrcnn_bbox_loss: 0.0151 - mrcnn_mask_loss: 0.0484 - val_loss: 1.0796 - val_rpn_class_loss: 0.0121 - val_rpn_bbox_loss: 0.2958 - val_mrcnn_class_loss: 0.0911 - val_mrcnn_bbox_loss: 0.1522 - val_mrcnn_mask_loss: 0.5284
Epoch 16/20
115/115 [==============================] - 542s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.0913 - rpn_class_loss: 8.9636e-04 - rpn_bbox_loss: 0.0277 - mrcnn_class_loss: 0.0038 - mrcnn_bbox_loss: 0.0176 - mrcnn_mask_loss: 0.0414 - val_loss: 1.2620 - val_rpn_class_loss: 0.0142 - val_rpn_bbox_loss: 0.3599 - val_mrcnn_class_loss: 0.1005 - val_mrcnn_bbox_loss: 0.1851 - val_mrcnn_mask_loss: 0.6022
Epoch 17/20
115/115 [==============================] - 541s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.0907 - rpn_class_loss: 9.1597e-04 - rpn_bbox_loss: 0.0265 - mrcnn_class_loss: 0.0027 - mrcnn_bbox_loss: 0.0189 - mrcnn_mask_loss: 0.0417 - val_loss: 1.1711 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 0.3185 - val_mrcnn_class_loss: 0.1538 - val_mrcnn_bbox_loss: 0.2396 - val_mrcnn_mask_loss: 0.4466
Epoch 18/20
115/115 [==============================] - 542s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.0983 - rpn_class_loss: 7.7699e-04 - rpn_bbox_loss: 0.0285 - mrcnn_class_loss: 0.0032 - mrcnn_bbox_loss: 0.0205 - mrcnn_mask_loss: 0.0453 - val_loss: 0.8641 - val_rpn_class_loss: 0.0141 - val_rpn_bbox_loss: 0.2756 - val_mrcnn_class_loss: 0.1232 - val_mrcnn_bbox_loss: 0.1234 - val_mrcnn_mask_loss: 0.3278
Epoch 19/20
115/115 [==============================] - 542s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.1164 - rpn_class_loss: 9.5586e-04 - rpn_bbox_loss: 0.0440 - mrcnn_class_loss: 0.0034 - mrcnn_bbox_loss: 0.0188 - mrcnn_mask_loss: 0.0492 - val_loss: 1.0430 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.2784 - val_mrcnn_class_loss: 0.1855 - val_mrcnn_bbox_loss: 0.2097 - val_mrcnn_mask_loss: 0.3533
Epoch 20/20
115/115 [==============================] - 543s 5s/step - batch: 57.0000 - size: 2.0000 - loss: 0.0976 - rpn_class_loss: 9.2043e-04 - rpn_bbox_loss: 0.0318 - mrcnn_class_loss: 0.0035 - mrcnn_bbox_loss: 0.0162 - mrcnn_mask_loss: 0.0453 - val_loss: 1.1380 - val_rpn_class_loss: 0.0151 - val_rpn_bbox_loss: 0.3272 - val_mrcnn_class_loss: 0.2376 - val_mrcnn_bbox_loss: 0.2176 - val_mrcnn_mask_loss: 0.3404
180.73 minutos